{
    "model": "JunHowie/Qwen3-4B-GPTQ-Int4",
    "quantization": "gptq",
    "dtype": "float16",
    "tensor_parallel_size": 1,
    "gpu_memory_utilization": 0.15,
    "max_model_len": 4096,
    "enable_prefix_caching": true,
    "disable_log_stats": false
}
