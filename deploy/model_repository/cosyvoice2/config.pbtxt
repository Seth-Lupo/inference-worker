# CosyVoice 2 - Text-to-Speech
# TensorRT-LLM backend for streaming TTS
#
# This is a Python backend wrapper that coordinates:
# - LLM component (text-to-speech tokens)
# - Flow decoder (tokens to audio)

name: "cosyvoice2"
backend: "python"
max_batch_size: 4

input [
  {
    name: "text"
    data_type: TYPE_STRING
    dims: [ 1 ]
  },
  {
    name: "speaker_id"
    data_type: TYPE_STRING
    dims: [ 1 ]
    optional: true
  },
  {
    name: "streaming"
    data_type: TYPE_BOOL
    dims: [ 1 ]
    optional: true
  }
]

output [
  {
    name: "audio"
    data_type: TYPE_FP32
    dims: [ -1 ]  # Variable length audio samples
  },
  {
    name: "sample_rate"
    data_type: TYPE_INT32
    dims: [ 1 ]
  }
]

instance_group [
  {
    count: 1
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]

dynamic_batching {
  preferred_batch_size: [ 1, 2, 4 ]
  max_queue_delay_microseconds: 50000
}

# Model parameters
parameters {
  key: "model_path"
  value: { string_value: "/models/cosyvoice2/1/pretrained_models/CosyVoice2-0.5B" }
}

parameters {
  key: "use_trt"
  value: { string_value: "true" }
}

parameters {
  key: "use_fp16"
  value: { string_value: "true" }
}

version_policy: { latest: { num_versions: 1 } }
