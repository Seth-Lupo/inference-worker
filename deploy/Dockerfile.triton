# =============================================================================
# Triton Inference Server - Voice Agent Stack
# =============================================================================
#
# Models:
#   - Qwen3 LLM (vLLM backend)
#   - T3 speech tokens (vLLM backend)
#   - Chatterbox TTS (Python backend)
#   - Parakeet ASR (Python backend + ONNX Runtime)
#
# Dependency Strategy:
#   1. Use NVIDIA's pre-built vLLM + torch (GPU optimized)
#   2. Avoid diffusers (imports torchvision which has ABI issues with NVIDIA torch)
#   3. Pin transformers < 4.48 (s3tokenizer aimv2 conflict)
#   4. Use --upgrade-strategy only-if-needed (preserve base packages)
#
# =============================================================================

FROM nvcr.io/nvidia/tritonserver:25.12-vllm-python-py3

# =============================================================================
# Environment Configuration
# =============================================================================

# vLLM: Use V0 engine (V1 incompatible with Triton's threading model)
ENV VLLM_USE_V1=0

# Disable xformers (causes triton kernel compatibility issues)
ENV XFORMERS_DISABLE_MEMORY_EFFICIENT_ATTENTION=1

# =============================================================================
# System Dependencies
# =============================================================================

RUN apt-get update && apt-get install -y --no-install-recommends \
        espeak-ng \
        libsndfile1 \
        ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# =============================================================================
# Python Dependencies
# =============================================================================

# Triton client for BLS (Python backend calling other Triton models)
RUN pip install --no-cache-dir tritonclient[grpc]

# Pin transformers to avoid aimv2 conflict with s3tokenizer
# (s3tokenizer registers model_type="aimv2", conflicts with transformers 4.48+)
RUN pip install --no-cache-dir --upgrade-strategy only-if-needed \
        "transformers>=4.45.0,<4.48.0"

# Audio processing
RUN pip install --no-cache-dir --upgrade-strategy only-if-needed \
        librosa \
        soundfile \
        scipy

# Chatterbox TTS / S3Gen dependencies
# Note: diffusers removed - using local diffusers_compat.py to avoid torchvision ABI issues
RUN pip install --no-cache-dir --upgrade-strategy only-if-needed \
        omegaconf \
        einops \
        conformer \
        "s3tokenizer>=0.3.0"

# Parakeet ASR (ONNX Runtime with CUDA)
RUN pip install --no-cache-dir --upgrade-strategy only-if-needed \
        onnxruntime-gpu

# Quantized model support (GPTQ, AWQ)
RUN pip install --no-cache-dir --upgrade-strategy only-if-needed \
        compressed-tensors

# =============================================================================
# Cleanup
# =============================================================================

RUN pip uninstall -y xformers 2>/dev/null || true && \
    rm -rf /root/.cache/pip /tmp/*

# =============================================================================
# Verification
# =============================================================================

RUN echo "============================================" && \
    echo "Package Versions:" && \
    echo "============================================" && \
    python3 -c "import torch; print(f'  torch:        {torch.__version__}')" && \
    python3 -c "import vllm; print(f'  vllm:         {vllm.__version__}')" && \
    python3 -c "import transformers; print(f'  transformers: {transformers.__version__}')" && \
    python3 -c "import numpy; print(f'  numpy:        {numpy.__version__}')" && \
    python3 -c "import librosa; print(f'  librosa:      {librosa.__version__}')" && \
    python3 -c "import onnxruntime; print(f'  onnxruntime:  {onnxruntime.__version__}')" && \
    python3 -c "import s3tokenizer; print('  s3tokenizer:  OK')" && \
    python3 -c "import conformer; print('  conformer:    OK')" && \
    echo "============================================" && \
    echo "Critical Ops Tests:" && \
    echo "============================================" && \
    python3 -c "from vllm import LLM; print('  vllm.LLM: OK')" && \
    python3 -c "import onnxruntime as ort; provs=ort.get_available_providers(); print(f'  ONNX providers: {provs}')" && \
    echo "============================================" && \
    echo "Triton Backends:" && \
    echo "============================================" && \
    ls -1 /opt/tritonserver/backends/ | sed 's/^/  /'
