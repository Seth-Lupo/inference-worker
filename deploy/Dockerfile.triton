# Custom Triton image with TensorRT-LLM + Python dependencies
# Using Triton 25.12 with TRT-LLM 1.0.0+ (Qwen3 TensorRT engine support)
FROM nvcr.io/nvidia/tritonserver:25.12-trtllm-python-py3

# Install system dependencies for audio processing
# espeak-ng: required by phonemizer for text-to-phoneme conversion
# libsndfile1: required by soundfile for audio I/O
RUN apt-get update && apt-get install -y --no-install-recommends \
        espeak-ng \
        libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Install grpcio as pre-built binary (skip slow source compilation)
RUN pip install --no-cache-dir --only-binary :all: grpcio grpcio-tools

# Install torchaudio (torch already in base image)
# --no-deps avoids reinstalling torch
RUN pip install --no-cache-dir --no-deps \
        torchaudio --index-url https://download.pytorch.org/whl/cu130

# Install Python packages for Parakeet ASR and CosyVoice TTS
# Split into groups to avoid dependency conflicts

# Core packages (binary only to avoid build issues)
RUN pip install --no-cache-dir --only-binary :all: \
        numpy scipy pyyaml

# ML frameworks
RUN pip install --no-cache-dir \
        transformers \
        sentencepiece \
        einops \
        pytorch-lightning==2.0.0 \
        diffusers \
        x-transformers \
        conformer

# Config/loading
RUN pip install --no-cache-dir \
        hydra-core \
        omegaconf \
        hyperpyyaml \
        pydantic

# Audio processing
RUN pip install --no-cache-dir \
        librosa \
        soundfile \
        pyworld \
        phonemizer \
        inflect \
        Unidecode

# ASR (Parakeet)
RUN pip install --no-cache-dir \
        sherpa-onnx \
        onnx2torch \
        onnxruntime-gpu

# Audio tokenization
RUN pip install --no-cache-dir \
        s3tokenizer \
        onnx \
        openai-whisper \
        wget \
        gdown

# Runtime dependencies:
# - CosyVoice source is mounted at /opt/CosyVoice (for cosyvoice.llm, cosyvoice.flow classes)
# - PYTHONPATH=/opt/CosyVoice is set in docker-compose.yml
# - Model assets are in /models/cosyvoice2_full/assets/

# Triton 25.12-trtllm-python-py3 includes:
# - TensorRT-LLM 1.0.0+ (Qwen3 TensorRT engine support)
# - Triton Inference Server with tensorrtllm + python backends
#
# IMPORTANT: Engines must be built with matching TRT-LLM version!
# Use build container: nvcr.io/nvidia/tritonserver:25.12-trtllm-python-py3

