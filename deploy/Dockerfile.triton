# Triton Inference Server with vLLM + Python backends
# For serving:
#   - Qwen3 LLM (vLLM backend)
#   - T3 speech token generator (vLLM backend)
#   - Chatterbox TTS (Python backend with torch.compile)
#   - Parakeet ASR (Python backend with ONNX Runtime GPU)
#
# Base image already includes: torch, transformers, huggingface_hub, tokenizers,
# safetensors, numpy (via vLLM). We only add what's missing.
#
# Note: torchaudio removed - replaced with pure torch/librosa implementations
# to avoid ABI compatibility issues with base image torch.
#
# 25.05 requires Driver 575+ (compatible with Driver 580)
FROM nvcr.io/nvidia/tritonserver:25.05-vllm-python-py3

# Disable xformers to avoid triton kernel compatibility issues
ENV XFORMERS_DISABLE_MEMORY_EFFICIENT_ATTENTION=1
ENV DIFFUSERS_NO_XFORMERS=1

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
        espeak-ng \
        libsndfile1 \
        ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Install Triton client for BLS (Python backend calling other Triton models)
RUN pip install --no-cache-dir tritonclient[grpc]

# CRITICAL: Get the exact torch version from the base image BEFORE any pip installs
# This prevents any package from accidentally upgrading/downgrading torch and breaking vLLM ABI
RUN TORCH_VERSION=$(python3 -c "import torch; print(torch.__version__.split('+')[0])") && \
    echo "Base image torch version: $TORCH_VERSION" && \
    pip install --no-cache-dir \
        "torch==$TORCH_VERSION" \
        librosa \
        soundfile \
        scipy

# Install torchvision matching the base torch version
# Use --no-deps to avoid pulling any additional torch dependencies
RUN pip install --no-cache-dir --no-deps torchvision

# Install S3Gen/Chatterbox dependencies (not in base image)
# diffusers 0.27+ avoids cached_download deprecation in new huggingface_hub
# Note: transformers, huggingface_hub, tokenizers, safetensors already in base via vLLM
# Use pip constraint to prevent torch version changes
RUN TORCH_VERSION=$(python3 -c "import torch; print(torch.__version__.split('+')[0])") && \
    pip install --no-cache-dir \
        "torch==$TORCH_VERSION" \
        omegaconf \
        einops \
        "diffusers>=0.27.0,<0.30.0" \
        conformer \
        s3tokenizer

# Remove xformers to prevent triton kernel compatibility issues
# Env vars alone don't prevent module-level imports in diffusers
RUN pip uninstall -y xformers || true

# Install ONNX Runtime GPU for Parakeet ASR
# Uses CUDA EP for GPU acceleration of ONNX models
RUN pip install --no-cache-dir onnxruntime-gpu
