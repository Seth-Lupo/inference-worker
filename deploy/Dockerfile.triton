# Custom Triton image with TensorRT-LLM + Python dependencies
# Using Triton 25.08 with TRT-LLM 0.21.0 (Qwen3 support requires >= 0.20.0)
FROM nvcr.io/nvidia/tritonserver:25.08-trtllm-python-py3

# Install Python packages for Parakeet ASR and CosyVoice TTS
RUN pip install --no-cache-dir \
    sherpa-onnx \
    onnxruntime-gpu \
    numpy \
    transformers \
    sentencepiece

# Triton 25.08-trtllm-python-py3 includes:
# - TensorRT-LLM 0.21.0 (Qwen3 support added in 0.20.0)
# - Triton Inference Server with tensorrtllm + python backends
#
# IMPORTANT: Engines must be built with matching TRT-LLM version!
# Use build container: nvcr.io/nvidia/tritonserver:25.08-trtllm-python-py3
